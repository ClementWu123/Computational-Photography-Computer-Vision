{"cells":[{"cell_type":"markdown","metadata":{"id":"WS8t69S5z1iM"},"source":["# Linear Perceptron"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":821,"status":"ok","timestamp":1699674577387,"user":{"displayName":"Keqi Wu","userId":"01628003544885842630"},"user_tz":300},"id":"XWCHXdqhMrYQ","outputId":"c2b6ec6b-a54b-4eb8-c15e-75932e9c2bf0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143,"status":"ok","timestamp":1699674578218,"user":{"displayName":"Keqi Wu","userId":"01628003544885842630"},"user_tz":300},"id":"qHSr_Yy_MxKX","outputId":"f4121714-ecb7-4f41-a889-fba4cb960737"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/CIS581/CIS_5810_Project_8_Linear_Perceptron_Student_Files_V2\n"]}],"source":["cd /content/drive/MyDrive/Colab Notebooks/CIS581/CIS_5810_Project_8_Linear_Perceptron_Student_Files_V2"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":108,"status":"ok","timestamp":1699675497437,"user":{"displayName":"Keqi Wu","userId":"01628003544885842630"},"user_tz":300},"id":"xjJ-a_PTz1iR"},"outputs":[],"source":["import numpy as np\n","import glob\n","from helperP import *\n","import time"]},{"cell_type":"markdown","metadata":{"id":"cUdUuZIOz1ih"},"source":["### Define linear perceptron class"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":142,"status":"ok","timestamp":1699675842052,"user":{"displayName":"Keqi Wu","userId":"01628003544885842630"},"user_tz":300},"id":"cc0b-Y5Rz1im"},"outputs":[],"source":["class PrimalPerceptron(object):\n","\tdef __init__(self, x, y, lr = 0.1, w = None, b = None):\n","\t\tnum_sample, num_dims = x.shape\n","\t\tnp.random.seed(0)\n","\t\t####################################\n","\t\t# TODO: YOUR CODE HEREï¼š init weights\n","\t\t# (Hint: You may find np.random.randn useful)\n","\t\t####################################\n","\t\tif not w: w = np.random.randn(num_dims,1)\n","\t\tif not b: b = np.random.randn(1)\n","\t\tself.x, self.y, self.w, self.b = x, y.reshape(-1,1), w, b\n","\t\tself.lr = lr\n","\n","\tdef predict(self):\n","\t\t####################################\n","\t\t# TODO: YOUR CODE HERE, forward\n","\t\t####################################\n","\t\tpred = (self.x @ self.w + self.b)\n","\t\ty_pred = np.where(pred \u003e 0, 1, -1).reshape(-1,1)\n","\t\treturn pred, y_pred\n","\n","\tdef update(self):\n","\t\t####################################\n","\t\t# TODO: YOUR CODE HERE, backward\n","\t\t####################################\n","\t\t# update the weights and bias\n","\t\tpred, y_pred = self.predict()\n","\t\tresid = self.y - y_pred\n","\t\tself.w += self.lr * (self.x.T @ resid)\n","\t\tself.b += self.lr * np.sum(resid)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146,"status":"ok","timestamp":1699675842924,"user":{"displayName":"Keqi Wu","userId":"01628003544885842630"},"user_tz":300},"id":"tvgDkYZgmTut","outputId":"b8d81d65-f4e2-4887-8bfc-e7c15b2dc71c"},"outputs":[{"name":"stdout","output_type":"stream","text":["test passed\n"]}],"source":["## Test ##\n","x = np.random.randn(10, 2)\n","y = np.random.randint(0, 2, size=(10, 1))\n","y[y == 0] = -1\n","p = PrimalPerceptron(x, y)\n","pred, y_pred = p.predict()\n","assert pred.shape[0] == 10\n","assert np.logical_or(y_pred == 1, y_pred == -1).all()\n","p.update()\n","assert p.w.shape[0] == x.shape[1]\n","assert p.b.shape[0] == 1\n","print('test passed')"]},{"cell_type":"markdown","metadata":{"id":"HOb4zzKWz1iz"},"source":["### Train linear perceptron"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1vTMqE8M9fa-n979hFvv93PkMCnVC5Pn2"},"id":"qGnN7ZOnz1i3","outputId":"021cd057-07b0-4b47-b702-b3d3a520afa4","scrolled":true},"outputs":[],"source":["if __name__ == '__main__':\n","    # Load data\n","    file_names = glob.glob('DATASET/data_emoji/*/*.*')\n","    reduced, images, labels = load_image(file_names)\n","\n","    reduced = reduced.reshape(reduced.shape[0], -1)\n","    # Instantiate Perceptron\n","    p = PrimalPerceptron(reduced, labels)\n","    # Iterate over data and update\n","\n","    plt.rcParams[\"figure.figsize\"] = [20, 20]\n","    for i in range(100):\n","        p.update()\n","        preds, y_hat = p.predict()\n","        visualize_results(images, preds, labels, None)\n"]},{"cell_type":"markdown","metadata":{"id":"Eif-t1P8Ltpx"},"source":["### Hyperparameter Tuning\n","In this part, we will take a look at the effect of different learning rate on model prediction accuracy and running time. Specifically, we would iterate through all learning rate in `[0.0001, 0.001, 0.01, 0.1, 1, 10]` and train the perceptron model based on it. For each learning rate, it will run 50 episodes to record the average running time and accuracy. In each episode, the model is trained 100 times.\n","\n","The running time for each episode is defined as the time interval betweeen model is first created and the model reaches 100% accuracy. If the model doesn't reach 100% accuracy, then the running time for this episode would be the whole 100 epoches running time. Take a look at the code cell below to see how it works."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10420,"status":"ok","timestamp":1699416041338,"user":{"displayName":"Keqi Wu","userId":"01628003544885842630"},"user_tz":300},"id":"I0Sv2XD-Ltpx","outputId":"dc13af65-a0e0-4e58-c066-ece680065eea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Learning rate lr = 1e-05: Reaching 90.00% accuracy in 0.023s.\n","Learning rate lr = 0.0001: Reaching 100.00% accuracy in 0.013s.\n","Learning rate lr = 0.001: Reaching 100.00% accuracy in 0.015s.\n","Learning rate lr = 0.01: Reaching 100.00% accuracy in 0.026s.\n","Learning rate lr = 0.1: Reaching 100.00% accuracy in 0.032s.\n","Learning rate lr = 1: Reaching 100.00% accuracy in 0.016s.\n","Learning rate lr = 10: Reaching 100.00% accuracy in 0.015s.\n"]}],"source":["# Read in necessary test files\n","file_names = glob.glob('DATASET/data_emoji/*/*.*')\n","reduced, images, labels = load_image(file_names)\n","reduced = reduced.reshape(reduced.shape[0], -1)\n","\n","# Define a list of hyperparameter for learning rate tuning\n","lr_set = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]\n","\n","# Training model with different learning rate\n","for lr in lr_set:\n","  # Initialize cost for current learning rate model\n","  cost = 0\n","  accuracy = 0\n","  # For each learning rate, run 50 episodes and keep track of average running time\n","  for episode in range(50):\n","    start = time.time()\n","    finish_before = False\n","    p = PrimalPerceptron(reduced, labels, lr)\n","    # Training model 100 times\n","    for i in range(100):\n","      p.update()\n","      preds, y_hat = p.predict()\n","      # The running time is defined as the time when the model reaches 100% accuracy\n","      if np.sum(y_hat == labels) == 20 and not finish_before:\n","        end = time.time()\n","        finish_before = True\n","    # If the model doesn't reach 100% accuracy in 100 epoches, then the end running time is defined as the whole 100 epoches running time\n","    if not finish_before:\n","        end = time.time()\n","    # Running time for one episode\n","    cost += end - start\n","    accuracy += np.sum(y_hat == labels)/20 * 100\n","  # Cost and accuracy for one learning rate model\n","  cost /= 50\n","  accuracy /= 50\n","  print('Learning rate lr = {}: Reaching {:.2f}% accuracy in {:.3f}s.'.format(lr, accuracy, cost))"]},{"cell_type":"markdown","metadata":{"id":"y1ddDB28Ltpy"},"source":["Discuss the effect of different learning rate on both the running time and model prediction accuracy. What do you think might cause the difference? Please include your answer in a separate cell in the Colab Notebook."]},{"cell_type":"markdown","metadata":{"id":"X8yHP64YLtpz"},"source":["Answer: Higher learning rate implies faster convergence rate. With a higher learning rate, the model running time will generally reduce, and model prediction accuracy will generally increase as the result is closer to the exact solution, vise versa. However, if the learning rate is too large, the result bounces around the exact solution, which will potentially increase the model running time and decrease the prediction accuracy. The difference depends on the complexity of data as it will affect the weights of the model. It also depends on the algorithm, as it will determine the optimization problem.\n","\n"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}},"vscode":{"interpreter":{"hash":"8b8940013284a1b229d803e2b39c8affb19055b93de71980f73f46f3bc3f114b"}}},"nbformat":4,"nbformat_minor":0}